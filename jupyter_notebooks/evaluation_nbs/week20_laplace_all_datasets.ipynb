{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66660abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seml\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "from scipy.stats import binned_statistic\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6642f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/fuchsgru/MastersThesis\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ef8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.constants as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120850f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'week20_laplace_all_datasets'\n",
    "collection = seml.database.get_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642af785",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_status = defaultdict(set)\n",
    "for r in collection.find():\n",
    "    by_status[r['status']].add(r['config']['data']['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28df587c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'COMPLETED': {'amazon_photo',\n",
       "              'citeseer',\n",
       "              'coauthor_cs',\n",
       "              'cora_full',\n",
       "              'pubmed'},\n",
       "             'KILLED': {'ogbn_arxiv'},\n",
       "             'PENDING': {'ogbn_arxiv'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58a3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_exps = [r for r in collection.find() if r['status'] == 'FAILED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106eabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_exps = [r for r in collection.find() if r['status'] == 'KILLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f106fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 526,\n",
       " 'batch_id': 7,\n",
       " 'status': 'KILLED',\n",
       " 'seml': {'executable': 'training_semi_supervised_node_classification.py',\n",
       "  'name': 'week20_dropout_all_datasets',\n",
       "  'output_dir': '/nfs/students/fuchsgru/seml_output/week20',\n",
       "  'working_dir': '/nfs/homedirs/fuchsgru/MastersThesis',\n",
       "  'conda_environment': 'base',\n",
       "  'source_files': [['model/prediction.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeaba')],\n",
       "   ['data/split.py', ObjectId('6241cea033a2eea9a7faeabc')],\n",
       "   ['model/build.py', ObjectId('6241cea033a2eea9a7faeabe')],\n",
       "   ['evaluation/pipeline/base.py', ObjectId('6241cea033a2eea9a7faeac0')],\n",
       "   ['data/__init__.py', ObjectId('6241cea033a2eea9a7faeac2')],\n",
       "   ['evaluation/lipschitz.py', ObjectId('6241cea033a2eea9a7faeac4')],\n",
       "   ['model/parametrization.py', ObjectId('6241cea033a2eea9a7faeac6')],\n",
       "   ['model/constants.py', ObjectId('6241cea033a2eea9a7faeac8')],\n",
       "   ['evaluation/__init__.py', ObjectId('6241cea033a2eea9a7faeaca')],\n",
       "   ['data/util.py', ObjectId('6241cea033a2eea9a7faeacc')],\n",
       "   ['evaluation/util.py', ObjectId('6241cea033a2eea9a7faeace')],\n",
       "   ['evaluation/pipeline/accuracy.py', ObjectId('6241cea033a2eea9a7faead0')],\n",
       "   ['data/transform.py', ObjectId('6241cea033a2eea9a7faead2')],\n",
       "   ['model/feature_reconstruction.py', ObjectId('6241cea033a2eea9a7faead4')],\n",
       "   ['model/appr_diffusion.py', ObjectId('6241cea033a2eea9a7faead6')],\n",
       "   ['model/losses.py', ObjectId('6241cea033a2eea9a7faead8')],\n",
       "   ['evaluation/pipeline/uncertainty_quantification.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeada')],\n",
       "   ['model/bgcn/gcn_conv.py', ObjectId('6241cea033a2eea9a7faeadc')],\n",
       "   ['model/gnn.py', ObjectId('6241cea033a2eea9a7faeade')],\n",
       "   ['model_registry.py', ObjectId('6241cea033a2eea9a7faeae0')],\n",
       "   ['model/nn.py', ObjectId('6241cea033a2eea9a7faeae2')],\n",
       "   ['evaluation/constants.py', ObjectId('6241cea033a2eea9a7faeae4')],\n",
       "   ['model/gdk.py', ObjectId('6241cea033a2eea9a7faeae6')],\n",
       "   ['evaluation/pipeline/features.py', ObjectId('6241cea033a2eea9a7faeae8')],\n",
       "   ['model/normalizing_flow.py', ObjectId('6241cea033a2eea9a7faeaea')],\n",
       "   ['evaluation/pipeline/visualization.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeaec')],\n",
       "   ['seed.py', ObjectId('6241cea033a2eea9a7faeaee')],\n",
       "   ['plot/util.py', ObjectId('6241cea033a2eea9a7faeaf0')],\n",
       "   ['model/semi_supervised_node_classification.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeaf2')],\n",
       "   ['evaluation/pipeline/lipschitz.py', ObjectId('6241cea033a2eea9a7faeaf4')],\n",
       "   ['data/gust_dataset.py', ObjectId('6241cea033a2eea9a7faeaf6')],\n",
       "   ['configuration.py', ObjectId('6241cea033a2eea9a7faeaf8')],\n",
       "   ['model/bayesian.py', ObjectId('6241cea033a2eea9a7faeafa')],\n",
       "   ['model/orthogonal.py', ObjectId('6241cea033a2eea9a7faeafc')],\n",
       "   ['plot/neighbours.py', ObjectId('6241cea033a2eea9a7faeafe')],\n",
       "   ['plot/__init__.py', ObjectId('6241cea033a2eea9a7faeb00')],\n",
       "   ['data/constants.py', ObjectId('6241cea033a2eea9a7faeb01')],\n",
       "   ['model/input_distance.py', ObjectId('6241cea033a2eea9a7faeb03')],\n",
       "   ['data/base.py', ObjectId('6241cea033a2eea9a7faeb05')],\n",
       "   ['evaluation/pipeline/validate_and_test.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeb07')],\n",
       "   ['evaluation/pipeline/structure.py', ObjectId('6241cea033a2eea9a7faeb09')],\n",
       "   ['model/reconstruction.py', ObjectId('6241cea033a2eea9a7faeb0b')],\n",
       "   ['log.py', ObjectId('6241cea033a2eea9a7faeb0d')],\n",
       "   ['evaluation/logging.py', ObjectId('6241cea033a2eea9a7faeb0f')],\n",
       "   ['evaluation/pipeline/calibration.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeb11')],\n",
       "   ['model/bgcn/bayesian.py', ObjectId('6241cea033a2eea9a7faeb13')],\n",
       "   ['model/bgcn/utils.py', ObjectId('6241cea033a2eea9a7faeb15')],\n",
       "   ['evaluation/pipeline/data.py', ObjectId('6241cea033a2eea9a7faeb17')],\n",
       "   ['evaluation/pipeline/shift.py', ObjectId('6241cea033a2eea9a7faeb19')],\n",
       "   ['evaluation/pipeline/logit_geometry.py',\n",
       "    ObjectId('6241cea033a2eea9a7faeb1b')],\n",
       "   ['evaluation/pipeline/feature_space_distance.py',\n",
       "    ObjectId('6241cea133a2eea9a7faeb1d')],\n",
       "   ['plot/calibration.py', ObjectId('6241cea133a2eea9a7faeb1f')],\n",
       "   ['plot/density.py', ObjectId('6241cea133a2eea9a7faeb21')],\n",
       "   ['model/parameterless.py', ObjectId('6241cea133a2eea9a7faeb23')],\n",
       "   ['evaluation/pipeline/__init__.py', ObjectId('6241cea133a2eea9a7faeb25')],\n",
       "   ['data/npz.py', ObjectId('6241cea133a2eea9a7faeb27')],\n",
       "   ['training_semi_supervised_node_classification.py',\n",
       "    ObjectId('6241cea133a2eea9a7faeb29')],\n",
       "   ['plot/perturbations.py', ObjectId('6241cea133a2eea9a7faeb2b')],\n",
       "   ['plot/logit_geometry.py', ObjectId('6241cea133a2eea9a7faeb2d')],\n",
       "   ['evaluation/pipeline/softmax.py', ObjectId('6241cea133a2eea9a7faeb2f')],\n",
       "   ['evaluation/callbacks.py', ObjectId('6241cea133a2eea9a7faeb31')],\n",
       "   ['model/density.py', ObjectId('6241cea133a2eea9a7faeb33')],\n",
       "   ['train.py', ObjectId('6241cea133a2eea9a7faeb35')],\n",
       "   ['util.py', ObjectId('6241cea133a2eea9a7faeb37')],\n",
       "   ['evaluation/pipeline/feature_space_density.py',\n",
       "    ObjectId('6241cea133a2eea9a7faeb39')],\n",
       "   ['plot/features.py', ObjectId('6241cea133a2eea9a7faeb3b')],\n",
       "   ['plot/histogram_evolution.py', ObjectId('6241cea133a2eea9a7faeb3d')],\n",
       "   ['model/dimensionality_reduction.py', ObjectId('6241cea133a2eea9a7faeb3f')],\n",
       "   ['model/__init__.py', ObjectId('6241cea133a2eea9a7faeb41')],\n",
       "   ['data/build.py', ObjectId('6241cea133a2eea9a7faeb43')],\n",
       "   ['metrics.py', ObjectId('6241cea133a2eea9a7faeb45')],\n",
       "   ['model/bgcn/__init__.py', ObjectId('6241cea133a2eea9a7faeb47')]],\n",
       "  'output_file': '/nfs/students/fuchsgru/seml_output/week20/week20_dropout_all_datasets_526.out'},\n",
       " 'slurm': {'experiments_per_job': 2,\n",
       "  'sbatch_options': {'time': '0-24:00',\n",
       "   'nodes': 1,\n",
       "   'cpus-per-task': 2,\n",
       "   'mem': '256G',\n",
       "   'gres': 'gpu:1',\n",
       "   'partition': 'gpu_large'},\n",
       "  'array_id': '6840487',\n",
       "  'task_id': 0},\n",
       " 'config': {'overwrite': 526,\n",
       "  'db_collection': 'week20_laplace_all_datasets',\n",
       "  'data': {'dataset': 'ogbn_arxiv',\n",
       "   'drop_train_vertices_portion': 0.1,\n",
       "   'ood_sampling_strategy': 'all',\n",
       "   'ood_type': 'perturbations',\n",
       "   'preprocessing': 'none',\n",
       "   'setting': 'transductive',\n",
       "   'split_type': 'uniform',\n",
       "   'test_portion_fixed': 0.2,\n",
       "   'train_portion': 20,\n",
       "   'type': 'npz'},\n",
       "  'ensemble': {'num_members': 1, 'num_samples': 10},\n",
       "  'evaluation': {'ignore_exceptions': False,\n",
       "   'log_plots': False,\n",
       "   'pipeline': [{'evaluate_on': ['val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs': {'remove_edges': True},\n",
       "     'name': 'no-edges_val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'val',\n",
       "     'type': 'EvaluateCalibration'},\n",
       "    {'evaluate_on': ['val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs': {'remove_edges': True},\n",
       "     'name': 'no-edges_val',\n",
       "     'type': 'EvaluateCalibration'},\n",
       "    {'base_data': 'ood-val',\n",
       "     'dataset_name': 'ber-val',\n",
       "     'log_plots': False,\n",
       "     'name': 'val',\n",
       "     'parameters': {'p': 0.5},\n",
       "     'perturbation_type': 'bernoulli',\n",
       "     'type': 'PerturbData'},\n",
       "    {'base_data': 'ood-val',\n",
       "     'dataset_name': 'normal-val',\n",
       "     'log_plots': False,\n",
       "     'name': 'val',\n",
       "     'parameters': {'scale': 1.0},\n",
       "     'perturbation_type': 'normal',\n",
       "     'type': 'PerturbData'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_val',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_val',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_val',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['ber-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_val',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_val',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_val',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_val',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_val',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['normal-val'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_val',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs': {'remove_edges': True},\n",
       "     'name': 'no-edges_test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'test',\n",
       "     'type': 'EvaluateCalibration'},\n",
       "    {'evaluate_on': ['test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs': {'remove_edges': True},\n",
       "     'name': 'no-edges_test',\n",
       "     'type': 'EvaluateCalibration'},\n",
       "    {'base_data': 'ood-test',\n",
       "     'dataset_name': 'ber-test',\n",
       "     'log_plots': False,\n",
       "     'name': 'test',\n",
       "     'parameters': {'p': 0.5},\n",
       "     'perturbation_type': 'bernoulli',\n",
       "     'type': 'PerturbData'},\n",
       "    {'base_data': 'ood-test',\n",
       "     'dataset_name': 'normal-test',\n",
       "     'log_plots': False,\n",
       "     'name': 'test',\n",
       "     'parameters': {'scale': 1.0},\n",
       "     'perturbation_type': 'normal',\n",
       "     'type': 'PerturbData'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_test',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'ber-no-edges_test',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_test',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['ber-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'ber_test',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_test',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'model_kwargs_evaluate': {'remove_edges': True},\n",
       "     'name': 'normal-no-edges_test',\n",
       "     'type': 'EvaluateLogitEnergy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_test',\n",
       "     'type': 'EvaluateAccuracy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_test',\n",
       "     'type': 'EvaluateSoftmaxEntropy'},\n",
       "    {'evaluate_on': ['normal-test'],\n",
       "     'log_plots': False,\n",
       "     'name': 'normal_test',\n",
       "     'type': 'EvaluateLogitEnergy'}],\n",
       "   'sample': True},\n",
       "  'model': {'activation': 'leaky_relu',\n",
       "   'hidden_sizes': [64],\n",
       "   'laplace': {'batch_size': 512, 'hessian_structure': 'diag'},\n",
       "   'leaky_relu_slope': 0.01,\n",
       "   'model_type': 'gcn_laplace',\n",
       "   'residual': False,\n",
       "   'use_bias': True,\n",
       "   'use_spectral_norm': False},\n",
       "  'run': {'args': ['model:dropout',\n",
       "    'model:drop_edge',\n",
       "    'data:setting',\n",
       "    'data:dataset'],\n",
       "   'initialization_idx': 0,\n",
       "   'name': 'laplace-dataset:3-setting:2-ood_type:per',\n",
       "   'split_idx': 0,\n",
       "   'use_default_configuration': True},\n",
       "  'seed': 295918098,\n",
       "  'training': {'early_stopping': {'min_delta': 0.01,\n",
       "    'mode': 'min',\n",
       "    'monitor': 'val_loss',\n",
       "    'patience': 50},\n",
       "   'gpus': 1,\n",
       "   'learning_rate': 0.001,\n",
       "   'max_epochs': 1000}},\n",
       " 'config_hash': '04a6628bac5bdb3fc110fc928578a6b9',\n",
       " 'add_time': datetime.datetime(2022, 3, 23, 12, 10, 44, 543000),\n",
       " 'git': {'path': 'https://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@github.com/WodkaRHR/MastersThesis.git',\n",
       "  'commit': '0eff47a7650c92cbcc987fc2457d0b74bde802d8',\n",
       "  'dirty': True},\n",
       " 'artifacts': [],\n",
       " 'captured_out': '2022-03-28 17:05:48 (INFO): Running command \\'train\\'\\n2022-03-28 17:05:48 (INFO): Started run with ID \"526\"\\n2022-03-28 17:05:48 (INFO): Set configuration value data.base_labels to default all\\n2022-03-28 17:05:48 (INFO): Set configuration value data.train_labels to default all\\n2022-03-28 17:05:48 (INFO): Set configuration value data.left_out_class_labels to default [\\'arxiv cs ai\\', \\'arxiv cs ne\\', \\'arxiv cs sc\\', \\'arxiv cs cv\\', \\'arxiv cs gr\\', \\'arxiv cs se\\', \\'arxiv cs lg\\', \\'arxiv cs ro\\', \\'arxiv cs cl\\', \\'arxiv cs ir\\']\\n2022-03-28 17:05:48 (INFO): Set configuration value data.preprocessing to default none\\n2022-03-28 17:05:48 (INFO): Set configuration value data.ood_sampling_strategy to default all\\n2022-03-28 17:05:48 (INFO): Set configuration value data.split_type to default predefined\\n2022-03-28 17:05:48 (INFO): Set configuration value data.type to default npz\\n2022-03-28 17:05:48 (INFO): Set configuration value data.drop_train_vertices_portion to default 0.1\\n2022-03-28 17:05:48 (INFO): Set configuration value model.hidden_sizes to default [256, 256]\\n2022-03-28 17:05:48 (INFO): Set configuration value data.base_labels to all\\n2022-03-28 17:05:48 (INFO): Set configuration value data.corpus_labels to all\\n2022-03-28 17:05:48 (INFO): Set configuration value data.left_out_class_labels to []\\n2022-03-28 17:05:48 (INFO): Logging to collection week20_laplace_all_datasets\\n2022-03-28 17:05:49 (INFO): Data Loading - Loaded adjacency matrix.\\n2022-03-28 17:05:52 (INFO): Data Loading - Built attribute matrix.\\n2022-03-28 17:05:56 (INFO): Splitting - Reduced to base labels\\nGlobal seed set to 1952926171\\nGPU available: True, used: True\\nTPU available: False, using: 0 TPU cores\\nIPU available: False, using: 0 IPUs\\n2022-03-28 17:06:12 (INFO): Loading pre-trained model from /nfs/students/fuchsgru/model_registry/3010022454.ckpt\\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\\n2022-03-28 17:06:27 (INFO): Decomposing classifier\\n2022-03-28 17:06:28 (INFO): Using device cuda:0\\nGlobal seed set to 1337\\n2022-03-28 17:06:29 (INFO): Fitting laplace posterior\\n2022-03-28 17:06:32 (INFO): Optimizing prior precision\\n2022-03-28 20:40:21 (INFO): <class \\'model.nn.GCNConv\\'> disabled cache.\\n2022-03-28 20:40:21 (INFO): <class \\'model.nn.GCNConv\\'> disabled cache.\\n2022-03-28 20:40:21 (INFO): <class \\'model.nn.GCNConv\\'> disabled cache.\\n2022-03-28 20:40:21 (INFO): Executing pipeline...\\n2022-03-28 20:40:21 (INFO): Evaluation Pipeline\\nlog_plots : False\\nignore_exceptions : False\\ngpus : False\\nEvaluateAccuracy : \"val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateAccuracy : \"no-edges_val\"\\n\\tKwargs to model calls : {\\'remove_edges\\': True}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateCalibration : \"val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'val\\']\\n\\tBins : 10\\n\\tEpsilon : 1e-12\\nEvaluateCalibration : \"no-edges_val\"\\n\\tKwargs to model calls : {\\'remove_edges\\': True}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'val\\']\\n\\tBins : 10\\n\\tEpsilon : 1e-12\\nPerturbData : \"val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tBased on : ood-val\\n\\tDataset name : ber-val\\n\\tType : bernoulli\\n\\tParameters : {\\'p\\': 0.5}\\nPerturbData : \"val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tBased on : ood-val\\n\\tDataset name : normal-val\\n\\tType : normal\\n\\tParameters : {\\'scale\\': 1.0}\\nEvaluateAccuracy : \"ber-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"ber-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"ber-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"ber_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"ber_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"ber_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"normal-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"normal-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"normal-no-edges_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"normal_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"normal_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"normal_val\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-val\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateAccuracy : \"no-edges_test\"\\n\\tKwargs to model calls : {\\'remove_edges\\': True}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateCalibration : \"test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'test\\']\\n\\tBins : 10\\n\\tEpsilon : 1e-12\\nEvaluateCalibration : \"no-edges_test\"\\n\\tKwargs to model calls : {\\'remove_edges\\': True}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'test\\']\\n\\tBins : 10\\n\\tEpsilon : 1e-12\\nPerturbData : \"test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tBased on : ood-test\\n\\tDataset name : ber-test\\n\\tType : bernoulli\\n\\tParameters : {\\'p\\': 0.5}\\nPerturbData : \"test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tBased on : ood-test\\n\\tDataset name : normal-test\\n\\tType : normal\\n\\tParameters : {\\'scale\\': 1.0}\\nEvaluateAccuracy : \"ber-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"ber-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"ber-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"ber_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"ber_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"ber_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'ber-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"normal-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"normal-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"normal-no-edges_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tKwargs to model calls (evaluate) : {\\'remove_edges\\': True}\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\nEvaluateAccuracy : \"normal_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood\\n\\tSeparate distributions tolerance : 0.0\\nEvaluateSoftmaxEntropy : \"normal_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tEpsilon for entropy calculation : 1e-12\\n\\tEpsilon for variance calculation : 1e-12\\nEvaluateLogitEnergy : \"normal_test\"\\n\\tKwargs to model calls : {}\\n\\tLog plots : False\\n\\tEvaluate on : [\\'normal-test\\']\\n\\tSeparate distributions by : ood-and-neighbourhood\\n\\tSeparate distributions tolerance : 0.0\\n\\tTemperature : 1.0\\n2022-03-28 20:40:21 (INFO): EVALUATION PIPELINE - Running EvaluateAccuracy : \"val\"...\\n',\n",
       " 'command': 'train',\n",
       " 'experiment': {'name': 'training_semi_supervised_node_classification',\n",
       "  'base_dir': '/tmp/3252be1f-48b1-4001-b78e-af1da66e0d15',\n",
       "  'sources': [['configuration.py', ObjectId('6241ceccc10bb2b5b5e0a9b3')],\n",
       "   ['data/build.py', ObjectId('6241ceccc10bb2b5b5e0a9b5')],\n",
       "   ['data/constants.py', ObjectId('6241ceccc10bb2b5b5e0a9b7')],\n",
       "   ['data/util.py', ObjectId('6241ceccc10bb2b5b5e0a9b9')],\n",
       "   ['evaluation/__init__.py', ObjectId('6241ceccc10bb2b5b5e0a9bb')],\n",
       "   ['evaluation/logging.py', ObjectId('6241ceccc10bb2b5b5e0a9bd')],\n",
       "   ['evaluation/pipeline/__init__.py', ObjectId('6241ceccc10bb2b5b5e0a9bf')],\n",
       "   ['evaluation/pipeline/base.py', ObjectId('6241ceccc10bb2b5b5e0a9c1')],\n",
       "   ['model/__init__.py', ObjectId('6241ceccc10bb2b5b5e0a9c3')],\n",
       "   ['model/build.py', ObjectId('6241ceccc10bb2b5b5e0a9c5')],\n",
       "   ['model/semi_supervised_node_classification.py',\n",
       "    ObjectId('6241ceccc10bb2b5b5e0a9c7')],\n",
       "   ['seed.py', ObjectId('6241ceccc10bb2b5b5e0a9c9')],\n",
       "   ['train.py', ObjectId('6241ceccc10bb2b5b5e0a9cb')],\n",
       "   ['training_semi_supervised_node_classification.py',\n",
       "    ObjectId('6241ceccc10bb2b5b5e0a9cd')],\n",
       "   ['util.py', ObjectId('6241ceccc10bb2b5b5e0a9cf')]],\n",
       "  'dependencies': ['attr==0.3.1',\n",
       "   'matplotlib==3.5.0',\n",
       "   'numpy==1.20.3',\n",
       "   'pytorch-lightning==1.5.10',\n",
       "   'sacred==0.8.2',\n",
       "   'seml==0.3.5',\n",
       "   'torch==1.10.1',\n",
       "   'torch-geometric==2.0.3'],\n",
       "  'repositories': [],\n",
       "  'mainfile': 'training_semi_supervised_node_classification.py'},\n",
       " 'format': 'MongoObserver-0.7.0',\n",
       " 'heartbeat': datetime.datetime(2022, 3, 28, 18, 44, 55, 94000),\n",
       " 'host': {'hostname': 'gpu16',\n",
       "  'os': ['Linux', 'Linux-5.4.0-94-generic-x86_64-with-glibc2.31'],\n",
       "  'python_version': '3.9.5',\n",
       "  'cpu': 'Intel(R) Xeon(R) Gold 5120 CPU @ 2.20GHz',\n",
       "  'gpus': {'gpus': [{'model': 'NVIDIA GeForce RTX 2080 Ti',\n",
       "     'total_memory': 11019,\n",
       "     'persistence_mode': False}],\n",
       "   'driver_version': '470.82.01'},\n",
       "  'ENV': {}},\n",
       " 'info': {},\n",
       " 'meta': {'command': 'train',\n",
       "  'options': {'--beat-interval': None,\n",
       "   '--capture': None,\n",
       "   '--comment': None,\n",
       "   '--debug': False,\n",
       "   '--enforce_clean': False,\n",
       "   '--file_storage': None,\n",
       "   '--force': True,\n",
       "   '--help': False,\n",
       "   '--loglevel': None,\n",
       "   '--mongo_db': None,\n",
       "   '--name': None,\n",
       "   '--pdb': False,\n",
       "   '--print-config': False,\n",
       "   '--priority': None,\n",
       "   '--queue': False,\n",
       "   '--s3': None,\n",
       "   '--sql': None,\n",
       "   '--tiny_db': None,\n",
       "   '--unobserved': False,\n",
       "   'with': True,\n",
       "   'UPDATE': ['overwrite=526',\n",
       "    \"db_collection='week20_laplace_all_datasets'\",\n",
       "    \"data={'dataset': 'ogbn_arxiv', 'drop_train_vertices_portion': 0.1, 'ood_sampling_strategy': 'all', 'ood_type': 'perturbations', 'preprocessing': 'none', 'setting': 'transductive', 'split_type': 'uniform', 'test_portion_fixed': 0.2, 'train_portion': 20, 'type': 'npz'}\",\n",
       "    \"ensemble={'num_members': 1, 'num_samples': 10}\",\n",
       "    \"evaluation={'ignore_exceptions': False, 'log_plots': False, 'pipeline': [{'evaluate_on': ['val'], 'log_plots': False, 'name': 'val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['val'], 'log_plots': False, 'model_kwargs': {'remove_edges': True}, 'name': 'no-edges_val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['val'], 'log_plots': False, 'name': 'val', 'type': 'EvaluateCalibration'}, {'evaluate_on': ['val'], 'log_plots': False, 'model_kwargs': {'remove_edges': True}, 'name': 'no-edges_val', 'type': 'EvaluateCalibration'}, {'base_data': 'ood-val', 'dataset_name': 'ber-val', 'log_plots': False, 'name': 'val', 'parameters': {'p': 0.5}, 'perturbation_type': 'bernoulli', 'type': 'PerturbData'}, {'base_data': 'ood-val', 'dataset_name': 'normal-val', 'log_plots': False, 'name': 'val', 'parameters': {'scale': 1.0}, 'perturbation_type': 'normal', 'type': 'PerturbData'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_val', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_val', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'name': 'ber_val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'name': 'ber_val', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['ber-val'], 'log_plots': False, 'name': 'ber_val', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_val', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_val', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'name': 'normal_val', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'name': 'normal_val', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['normal-val'], 'log_plots': False, 'name': 'normal_val', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['test'], 'log_plots': False, 'name': 'test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['test'], 'log_plots': False, 'model_kwargs': {'remove_edges': True}, 'name': 'no-edges_test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['test'], 'log_plots': False, 'name': 'test', 'type': 'EvaluateCalibration'}, {'evaluate_on': ['test'], 'log_plots': False, 'model_kwargs': {'remove_edges': True}, 'name': 'no-edges_test', 'type': 'EvaluateCalibration'}, {'base_data': 'ood-test', 'dataset_name': 'ber-test', 'log_plots': False, 'name': 'test', 'parameters': {'p': 0.5}, 'perturbation_type': 'bernoulli', 'type': 'PerturbData'}, {'base_data': 'ood-test', 'dataset_name': 'normal-test', 'log_plots': False, 'name': 'test', 'parameters': {'scale': 1.0}, 'perturbation_type': 'normal', 'type': 'PerturbData'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_test', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'ber-no-edges_test', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'name': 'ber_test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'name': 'ber_test', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['ber-test'], 'log_plots': False, 'name': 'ber_test', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_test', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'model_kwargs_evaluate': {'remove_edges': True}, 'name': 'normal-no-edges_test', 'type': 'EvaluateLogitEnergy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'name': 'normal_test', 'type': 'EvaluateAccuracy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'name': 'normal_test', 'type': 'EvaluateSoftmaxEntropy'}, {'evaluate_on': ['normal-test'], 'log_plots': False, 'name': 'normal_test', 'type': 'EvaluateLogitEnergy'}], 'sample': True}\",\n",
       "    \"model={'activation': 'leaky_relu', 'hidden_sizes': [64], 'laplace': {'batch_size': 512, 'hessian_structure': 'diag'}, 'leaky_relu_slope': 0.01, 'model_type': 'gcn_laplace', 'residual': False, 'use_bias': True, 'use_spectral_norm': False}\",\n",
       "    \"run={'args': ['model:dropout', 'model:drop_edge', 'data:setting', 'data:dataset'], 'initialization_idx': 0, 'name': 'laplace-dataset:3-setting:2-ood_type:per', 'split_idx': 0, 'use_default_configuration': True}\",\n",
       "    'seed=295918098',\n",
       "    \"training={'early_stopping': {'min_delta': 0.01, 'mode': 'min', 'monitor': 'val_loss', 'patience': 50}, 'gpus': 1, 'learning_rate': 0.001, 'max_epochs': 1000}\"],\n",
       "   'help': False,\n",
       "   'COMMAND': None}},\n",
       " 'resources': [],\n",
       " 'start_time': datetime.datetime(2022, 3, 28, 15, 5, 48, 654000),\n",
       " 'result': None,\n",
       " 'fail_trace': ['\\tSeparate distributions tolerance : 0.0\\n',\n",
       "  '\\tTemperature : 1.0\\n',\n",
       "  '2022-03-28 20:40:21 (INFO): EVALUATION PIPELINE - Running EvaluateAccuracy : \"val\"...\\n',\n",
       "  'Killed\\n']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912b2185",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6a95b08e7c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ex' is not defined"
     ]
    }
   ],
   "source": [
    "set(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5de59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(failed_exps[0]['fail_trace']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(failed_exps[0]['captured_out']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fa88dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d3b9efea33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfailed_exps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "failed_exps[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c570b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection = seml.database.get_collection(collection_name)\n",
    "experiments = [{'config' : r['config'], 'result' : r['result'], 'id' : r['_id']} for r in collection.find() if r['status'] in ('COMPLETED',)]\n",
    "for ex in experiments:\n",
    "    # print(ex['result'].keys())\n",
    "    ex['metrics'] = ex['result']['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b9535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'Metric'\n",
    "OOD_AUROC = 'OOD AUC-ROC'\n",
    "OOD_AUCPR = 'OOD AUC-PR'\n",
    "MISCLASSICIFACTION_AUROC = 'Misclassification AUC-ROC'\n",
    "MISCLASSICIFACTION_AUCPR = 'Misclassification AUC-PR'\n",
    "\n",
    "DATASET = 'Dataset'\n",
    "\n",
    "SETTING = 'Setting'\n",
    "HYBRID = 'Inductive'\n",
    "TRANSDUCTIVE = 'Transductive'\n",
    "LOC = 'Leave Out Classes'\n",
    "NORMAL = 'Normal'\n",
    "BERNOULLI = 'Bernoulli'\n",
    "NO_EDGES = 'No Edges'\n",
    "PROXY = 'Proxy'\n",
    "EXPERIMENT = 'Experiment'\n",
    "\n",
    "OOD_TYPE = 'OOD Type'\n",
    "\n",
    "\n",
    "RESIDUAL = 'Residual'\n",
    "SPECTRAL_NORM = 'Spectral Norm'\n",
    "WEIGHT_SCALE = 'Weight Scale'\n",
    "LOWER_LIPSCHITZ = 'Empirical Lower Lipschitz Bound'\n",
    "UPPER_LIPSCHITZ = 'Empirical Upper Lipschitz Bound'\n",
    "\n",
    "\n",
    "\n",
    "EPISTEMIC = 'Epistemic'\n",
    "ALEATORIC = 'Aleatoric'\n",
    "\n",
    "ACCURACY = 'Accuracy'\n",
    "ACCURACY_ID = 'In-distribution Accuracy'\n",
    "ECE = 'Expected Calibration Error'\n",
    "\n",
    "MODEL = 'Model'\n",
    "DROPOUT = 'Dropout'\n",
    "DROP_EDGE = 'Drop Edge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aadc2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe742a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proxy, data_acc_ece = [], []\n",
    "for ex in experiments:\n",
    "    cfg = ex['config']\n",
    "    base = {\n",
    "        SETTING : {dc.HYBRID : HYBRID, dc.TRANSDUCTIVE : TRANSDUCTIVE}[cfg['data']['setting']],\n",
    "        DATASET : cfg['data']['dataset'],\n",
    "    }\n",
    "    data_acc_ece.append(base | {\n",
    "        OOD_TYPE : cfg['data']['ood_type'],\n",
    "        ACCURACY : ex['metrics'][f'accuracy_{mode}_{mode}'][0],\n",
    "        ECE : ex['metrics'][f'ece_{mode}_{mode}'][0]['value'],\n",
    "    })\n",
    "    if cfg['data']['ood_type'] == dc.PERTURBATION:\n",
    "        ood_types = (\n",
    "            (BERNOULLI, 'ber'),\n",
    "            (NORMAL, 'normal'),\n",
    "        )\n",
    "    elif cfg['data']['ood_type'] == dc.LEFT_OUT_CLASSES:\n",
    "        ood_types = (\n",
    "            (LOC, 'loc'),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(cfg['data']['ood_type'])\n",
    "    \n",
    "    for no_edge_suffix, no_edges in (('-no-edges', True), ('', False)):\n",
    "    \n",
    "        for ood_type, ood_name in ood_types:\n",
    "            for proxy, proxy_name in ((ALEATORIC, 'expected-softmax-entropy'), (EPISTEMIC, 'mutual-information')):\n",
    "                data_proxy += [\n",
    "                    base | {\n",
    "                        EXPERIMENT : ood_type,\n",
    "                        PROXY : proxy,\n",
    "                        OOD_AUROC : ex['metrics'][f'ood_auroc_{proxy_name}_{ood_name}{no_edge_suffix}_{mode}'][0]['value'],\n",
    "                        OOD_AUCPR : ex['metrics'][f'ood_aucpr_{proxy_name}_{ood_name}{no_edge_suffix}_{mode}'][0]['value'],\n",
    "                        MISCLASSICIFACTION_AUROC : ex['metrics'][f'misclassification_auroc_{proxy_name}_{ood_name}{no_edge_suffix}_{mode}'][0]['value'],\n",
    "                        MISCLASSICIFACTION_AUCPR : ex['metrics'][f'misclassification_aucpr_{proxy_name}_{ood_name}{no_edge_suffix}_{mode}'][0]['value'],\n",
    "                        NO_EDGES : no_edges,\n",
    "                    }\n",
    "                ]\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "df_proxy = pd.DataFrame(data_proxy)\n",
    "df_acc_ece = pd.DataFrame(data_acc_ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269d5346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Setting</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>OOD Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Expected Calibration Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transductive</td>\n",
       "      <td>cora_full</td>\n",
       "      <td>left-out-classes</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.568850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transductive</td>\n",
       "      <td>cora_full</td>\n",
       "      <td>left-out-classes</td>\n",
       "      <td>0.758893</td>\n",
       "      <td>0.517596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transductive</td>\n",
       "      <td>cora_full</td>\n",
       "      <td>left-out-classes</td>\n",
       "      <td>0.812379</td>\n",
       "      <td>0.553822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transductive</td>\n",
       "      <td>cora_full</td>\n",
       "      <td>left-out-classes</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.533692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transductive</td>\n",
       "      <td>cora_full</td>\n",
       "      <td>left-out-classes</td>\n",
       "      <td>0.816092</td>\n",
       "      <td>0.555870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>amazon_photo</td>\n",
       "      <td>perturbations</td>\n",
       "      <td>0.882742</td>\n",
       "      <td>0.638955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>amazon_photo</td>\n",
       "      <td>perturbations</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>amazon_photo</td>\n",
       "      <td>perturbations</td>\n",
       "      <td>0.907268</td>\n",
       "      <td>0.660601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>amazon_photo</td>\n",
       "      <td>perturbations</td>\n",
       "      <td>0.886855</td>\n",
       "      <td>0.639863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>amazon_photo</td>\n",
       "      <td>perturbations</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>0.628687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Setting       Dataset          OOD Type  Accuracy  \\\n",
       "0    Transductive     cora_full  left-out-classes  0.832031   \n",
       "1    Transductive     cora_full  left-out-classes  0.758893   \n",
       "2    Transductive     cora_full  left-out-classes  0.812379   \n",
       "3    Transductive     cora_full  left-out-classes  0.792157   \n",
       "4    Transductive     cora_full  left-out-classes  0.816092   \n",
       "..            ...           ...               ...       ...   \n",
       "495     Inductive  amazon_photo     perturbations  0.882742   \n",
       "496     Inductive  amazon_photo     perturbations  0.919368   \n",
       "497     Inductive  amazon_photo     perturbations  0.907268   \n",
       "498     Inductive  amazon_photo     perturbations  0.886855   \n",
       "499     Inductive  amazon_photo     perturbations  0.874687   \n",
       "\n",
       "     Expected Calibration Error  \n",
       "0                      0.568850  \n",
       "1                      0.517596  \n",
       "2                      0.553822  \n",
       "3                      0.533692  \n",
       "4                      0.555870  \n",
       "..                          ...  \n",
       "495                    0.638955  \n",
       "496                    0.665100  \n",
       "497                    0.660601  \n",
       "498                    0.639863  \n",
       "499                    0.628687  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e19154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_mean_and_std(group):\n",
    "    mean = group.mean()\n",
    "    std = group.std()\n",
    "    return f'{mean:.2f}  {std:.2f}'\n",
    "    return mean\n",
    "\n",
    "df_proxy_agg = df_proxy.groupby([SETTING, DATASET, EXPERIMENT, NO_EDGES, PROXY]).agg(agg_mean_and_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3cf5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_proxy_agg.reset_index()\n",
    "df_tmp = df_tmp.melt(id_vars=[SETTING, DATASET, EXPERIMENT, NO_EDGES, PROXY], value_vars = [OOD_AUROC, OOD_AUCPR, MISCLASSICIFACTION_AUROC, MISCLASSICIFACTION_AUCPR], var_name='Metric')\n",
    "df_tmp = df_tmp[(df_tmp[METRIC] == OOD_AUROC) | (df_tmp[METRIC] == OOD_AUCPR)]\n",
    "df_tmp = df_tmp.pivot(index=[SETTING, DATASET, PROXY], columns=[METRIC, EXPERIMENT, NO_EDGES]).T.sort_index().T\n",
    "df_tmp.to_csv('~/laplace_all_datasets_ood_detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16eef468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OOD AUC-PR</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OOD AUC-ROC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Bernoulli</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Leave Out Classes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Normal</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Bernoulli</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Leave Out Classes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>No Edges</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setting</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Proxy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Inductive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">amazon_photo</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.50  0.02</td>\n",
       "      <td>0.80  0.04</td>\n",
       "      <td>0.71  0.07</td>\n",
       "      <td>0.52  0.05</td>\n",
       "      <td>0.47  0.04</td>\n",
       "      <td>0.33  0.02</td>\n",
       "      <td>0.51  0.02</td>\n",
       "      <td>0.79  0.04</td>\n",
       "      <td>0.81  0.05</td>\n",
       "      <td>0.74  0.04</td>\n",
       "      <td>0.48  0.03</td>\n",
       "      <td>0.18  0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.50  0.02</td>\n",
       "      <td>0.75  0.04</td>\n",
       "      <td>0.72  0.07</td>\n",
       "      <td>0.47  0.04</td>\n",
       "      <td>0.49  0.03</td>\n",
       "      <td>0.37  0.02</td>\n",
       "      <td>0.51  0.02</td>\n",
       "      <td>0.71  0.03</td>\n",
       "      <td>0.82  0.05</td>\n",
       "      <td>0.71  0.03</td>\n",
       "      <td>0.53  0.03</td>\n",
       "      <td>0.32  0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">citeseer</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.76  0.01</td>\n",
       "      <td>0.94  0.03</td>\n",
       "      <td>0.61  0.11</td>\n",
       "      <td>0.47  0.08</td>\n",
       "      <td>0.57  0.03</td>\n",
       "      <td>0.51  0.02</td>\n",
       "      <td>0.53  0.03</td>\n",
       "      <td>0.84  0.06</td>\n",
       "      <td>0.80  0.07</td>\n",
       "      <td>0.69  0.09</td>\n",
       "      <td>0.18  0.03</td>\n",
       "      <td>0.02  0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.78  0.04</td>\n",
       "      <td>0.86  0.03</td>\n",
       "      <td>0.44  0.11</td>\n",
       "      <td>0.38  0.06</td>\n",
       "      <td>0.73  0.06</td>\n",
       "      <td>0.73  0.08</td>\n",
       "      <td>0.56  0.05</td>\n",
       "      <td>0.67  0.06</td>\n",
       "      <td>0.61  0.11</td>\n",
       "      <td>0.56  0.05</td>\n",
       "      <td>0.61  0.08</td>\n",
       "      <td>0.65  0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">coauthor_cs</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.59  0.02</td>\n",
       "      <td>1.00  0.00</td>\n",
       "      <td>0.83  0.09</td>\n",
       "      <td>0.77  0.06</td>\n",
       "      <td>0.52  0.03</td>\n",
       "      <td>0.39  0.02</td>\n",
       "      <td>0.57  0.01</td>\n",
       "      <td>0.99  0.01</td>\n",
       "      <td>0.95  0.03</td>\n",
       "      <td>0.92  0.02</td>\n",
       "      <td>0.50  0.03</td>\n",
       "      <td>0.26  0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.59  0.02</td>\n",
       "      <td>0.87  0.02</td>\n",
       "      <td>0.67  0.05</td>\n",
       "      <td>0.65  0.06</td>\n",
       "      <td>0.59  0.03</td>\n",
       "      <td>0.52  0.03</td>\n",
       "      <td>0.55  0.01</td>\n",
       "      <td>0.76  0.03</td>\n",
       "      <td>0.77  0.03</td>\n",
       "      <td>0.78  0.02</td>\n",
       "      <td>0.60  0.02</td>\n",
       "      <td>0.50  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cora_full</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.61  0.03</td>\n",
       "      <td>0.95  0.03</td>\n",
       "      <td>0.84  0.06</td>\n",
       "      <td>0.69  0.05</td>\n",
       "      <td>0.45  0.04</td>\n",
       "      <td>0.38  0.03</td>\n",
       "      <td>0.52  0.03</td>\n",
       "      <td>0.91  0.05</td>\n",
       "      <td>0.93  0.03</td>\n",
       "      <td>0.84  0.03</td>\n",
       "      <td>0.31  0.05</td>\n",
       "      <td>0.12  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.61  0.03</td>\n",
       "      <td>0.83  0.03</td>\n",
       "      <td>0.58  0.05</td>\n",
       "      <td>0.57  0.05</td>\n",
       "      <td>0.52  0.04</td>\n",
       "      <td>0.44  0.05</td>\n",
       "      <td>0.52  0.06</td>\n",
       "      <td>0.71  0.04</td>\n",
       "      <td>0.72  0.04</td>\n",
       "      <td>0.67  0.05</td>\n",
       "      <td>0.48  0.05</td>\n",
       "      <td>0.28  0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pubmed</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.68  0.02</td>\n",
       "      <td>0.78  0.06</td>\n",
       "      <td>0.23  0.02</td>\n",
       "      <td>0.25  0.04</td>\n",
       "      <td>0.49  0.02</td>\n",
       "      <td>0.44  0.01</td>\n",
       "      <td>0.57  0.02</td>\n",
       "      <td>0.61  0.09</td>\n",
       "      <td>0.50  0.04</td>\n",
       "      <td>0.53  0.03</td>\n",
       "      <td>0.28  0.03</td>\n",
       "      <td>0.12  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.73  0.04</td>\n",
       "      <td>0.86  0.05</td>\n",
       "      <td>0.23  0.02</td>\n",
       "      <td>0.24  0.02</td>\n",
       "      <td>0.54  0.03</td>\n",
       "      <td>0.50  0.04</td>\n",
       "      <td>0.63  0.05</td>\n",
       "      <td>0.79  0.06</td>\n",
       "      <td>0.50  0.03</td>\n",
       "      <td>0.53  0.02</td>\n",
       "      <td>0.41  0.05</td>\n",
       "      <td>0.30  0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Transductive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">amazon_photo</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.51  0.02</td>\n",
       "      <td>0.78  0.06</td>\n",
       "      <td>0.65  0.09</td>\n",
       "      <td>0.58  0.03</td>\n",
       "      <td>0.45  0.04</td>\n",
       "      <td>0.32  0.02</td>\n",
       "      <td>0.53  0.03</td>\n",
       "      <td>0.77  0.05</td>\n",
       "      <td>0.76  0.06</td>\n",
       "      <td>0.75  0.02</td>\n",
       "      <td>0.49  0.02</td>\n",
       "      <td>0.18  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.50  0.03</td>\n",
       "      <td>0.73  0.06</td>\n",
       "      <td>0.67  0.09</td>\n",
       "      <td>0.51  0.03</td>\n",
       "      <td>0.48  0.05</td>\n",
       "      <td>0.35  0.03</td>\n",
       "      <td>0.52  0.02</td>\n",
       "      <td>0.70  0.04</td>\n",
       "      <td>0.78  0.05</td>\n",
       "      <td>0.71  0.03</td>\n",
       "      <td>0.53  0.03</td>\n",
       "      <td>0.30  0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">citeseer</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.69  0.06</td>\n",
       "      <td>0.97  0.02</td>\n",
       "      <td>0.59  0.17</td>\n",
       "      <td>0.43  0.17</td>\n",
       "      <td>0.37  0.03</td>\n",
       "      <td>0.33  0.02</td>\n",
       "      <td>0.68  0.05</td>\n",
       "      <td>0.96  0.04</td>\n",
       "      <td>0.84  0.09</td>\n",
       "      <td>0.71  0.15</td>\n",
       "      <td>0.23  0.05</td>\n",
       "      <td>0.08  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.63  0.05</td>\n",
       "      <td>0.75  0.05</td>\n",
       "      <td>0.49  0.16</td>\n",
       "      <td>0.40  0.15</td>\n",
       "      <td>0.47  0.05</td>\n",
       "      <td>0.45  0.08</td>\n",
       "      <td>0.58  0.05</td>\n",
       "      <td>0.64  0.06</td>\n",
       "      <td>0.71  0.11</td>\n",
       "      <td>0.69  0.13</td>\n",
       "      <td>0.50  0.08</td>\n",
       "      <td>0.45  0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">coauthor_cs</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.56  0.02</td>\n",
       "      <td>1.00  0.01</td>\n",
       "      <td>0.66  0.16</td>\n",
       "      <td>0.64  0.09</td>\n",
       "      <td>0.48  0.02</td>\n",
       "      <td>0.35  0.01</td>\n",
       "      <td>0.61  0.01</td>\n",
       "      <td>1.00  0.01</td>\n",
       "      <td>0.89  0.06</td>\n",
       "      <td>0.87  0.05</td>\n",
       "      <td>0.52  0.02</td>\n",
       "      <td>0.27  0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.55  0.02</td>\n",
       "      <td>0.87  0.01</td>\n",
       "      <td>0.58  0.13</td>\n",
       "      <td>0.54  0.10</td>\n",
       "      <td>0.54  0.02</td>\n",
       "      <td>0.48  0.02</td>\n",
       "      <td>0.57  0.02</td>\n",
       "      <td>0.77  0.03</td>\n",
       "      <td>0.75  0.04</td>\n",
       "      <td>0.78  0.04</td>\n",
       "      <td>0.61  0.02</td>\n",
       "      <td>0.52  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cora_full</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.57  0.03</td>\n",
       "      <td>0.94  0.04</td>\n",
       "      <td>0.87  0.04</td>\n",
       "      <td>0.75  0.06</td>\n",
       "      <td>0.35  0.03</td>\n",
       "      <td>0.30  0.02</td>\n",
       "      <td>0.61  0.02</td>\n",
       "      <td>0.92  0.05</td>\n",
       "      <td>0.95  0.02</td>\n",
       "      <td>0.90  0.04</td>\n",
       "      <td>0.33  0.03</td>\n",
       "      <td>0.18  0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.55  0.03</td>\n",
       "      <td>0.82  0.04</td>\n",
       "      <td>0.59  0.08</td>\n",
       "      <td>0.63  0.09</td>\n",
       "      <td>0.43  0.04</td>\n",
       "      <td>0.37  0.04</td>\n",
       "      <td>0.59  0.05</td>\n",
       "      <td>0.75  0.05</td>\n",
       "      <td>0.74  0.05</td>\n",
       "      <td>0.73  0.07</td>\n",
       "      <td>0.52  0.05</td>\n",
       "      <td>0.38  0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pubmed</th>\n",
       "      <th>Aleatoric</th>\n",
       "      <td>0.57  0.03</td>\n",
       "      <td>0.73  0.12</td>\n",
       "      <td>0.24  0.09</td>\n",
       "      <td>0.23  0.08</td>\n",
       "      <td>0.35  0.02</td>\n",
       "      <td>0.31  0.01</td>\n",
       "      <td>0.61  0.03</td>\n",
       "      <td>0.69  0.13</td>\n",
       "      <td>0.58  0.14</td>\n",
       "      <td>0.56  0.11</td>\n",
       "      <td>0.31  0.03</td>\n",
       "      <td>0.16  0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic</th>\n",
       "      <td>0.58  0.02</td>\n",
       "      <td>0.76  0.11</td>\n",
       "      <td>0.24  0.10</td>\n",
       "      <td>0.21  0.07</td>\n",
       "      <td>0.38  0.02</td>\n",
       "      <td>0.35  0.03</td>\n",
       "      <td>0.62  0.02</td>\n",
       "      <td>0.76  0.10</td>\n",
       "      <td>0.58  0.14</td>\n",
       "      <td>0.56  0.11</td>\n",
       "      <td>0.39  0.03</td>\n",
       "      <td>0.29  0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           value               \\\n",
       "Metric                                OOD AUC-PR                \n",
       "Experiment                             Bernoulli                \n",
       "No Edges                                   False         True   \n",
       "Setting      Dataset      Proxy                                 \n",
       "Inductive    amazon_photo Aleatoric  0.50  0.02  0.80  0.04   \n",
       "                          Epistemic  0.50  0.02  0.75  0.04   \n",
       "             citeseer     Aleatoric  0.76  0.01  0.94  0.03   \n",
       "                          Epistemic  0.78  0.04  0.86  0.03   \n",
       "             coauthor_cs  Aleatoric  0.59  0.02  1.00  0.00   \n",
       "                          Epistemic  0.59  0.02  0.87  0.02   \n",
       "             cora_full    Aleatoric  0.61  0.03  0.95  0.03   \n",
       "                          Epistemic  0.61  0.03  0.83  0.03   \n",
       "             pubmed       Aleatoric  0.68  0.02  0.78  0.06   \n",
       "                          Epistemic  0.73  0.04  0.86  0.05   \n",
       "Transductive amazon_photo Aleatoric  0.51  0.02  0.78  0.06   \n",
       "                          Epistemic  0.50  0.03  0.73  0.06   \n",
       "             citeseer     Aleatoric  0.69  0.06  0.97  0.02   \n",
       "                          Epistemic  0.63  0.05  0.75  0.05   \n",
       "             coauthor_cs  Aleatoric  0.56  0.02  1.00  0.01   \n",
       "                          Epistemic  0.55  0.02  0.87  0.01   \n",
       "             cora_full    Aleatoric  0.57  0.03  0.94  0.04   \n",
       "                          Epistemic  0.55  0.03  0.82  0.04   \n",
       "             pubmed       Aleatoric  0.57  0.03  0.73  0.12   \n",
       "                          Epistemic  0.58  0.02  0.76  0.11   \n",
       "\n",
       "                                                                    \\\n",
       "Metric                                                               \n",
       "Experiment                          Leave Out Classes                \n",
       "No Edges                                        False         True   \n",
       "Setting      Dataset      Proxy                                      \n",
       "Inductive    amazon_photo Aleatoric       0.71  0.07  0.52  0.05   \n",
       "                          Epistemic       0.72  0.07  0.47  0.04   \n",
       "             citeseer     Aleatoric       0.61  0.11  0.47  0.08   \n",
       "                          Epistemic       0.44  0.11  0.38  0.06   \n",
       "             coauthor_cs  Aleatoric       0.83  0.09  0.77  0.06   \n",
       "                          Epistemic       0.67  0.05  0.65  0.06   \n",
       "             cora_full    Aleatoric       0.84  0.06  0.69  0.05   \n",
       "                          Epistemic       0.58  0.05  0.57  0.05   \n",
       "             pubmed       Aleatoric       0.23  0.02  0.25  0.04   \n",
       "                          Epistemic       0.23  0.02  0.24  0.02   \n",
       "Transductive amazon_photo Aleatoric       0.65  0.09  0.58  0.03   \n",
       "                          Epistemic       0.67  0.09  0.51  0.03   \n",
       "             citeseer     Aleatoric       0.59  0.17  0.43  0.17   \n",
       "                          Epistemic       0.49  0.16  0.40  0.15   \n",
       "             coauthor_cs  Aleatoric       0.66  0.16  0.64  0.09   \n",
       "                          Epistemic       0.58  0.13  0.54  0.10   \n",
       "             cora_full    Aleatoric       0.87  0.04  0.75  0.06   \n",
       "                          Epistemic       0.59  0.08  0.63  0.09   \n",
       "             pubmed       Aleatoric       0.24  0.09  0.23  0.08   \n",
       "                          Epistemic       0.24  0.10  0.21  0.07   \n",
       "\n",
       "                                                                            \\\n",
       "Metric                                                         OOD AUC-ROC   \n",
       "Experiment                                Normal                 Bernoulli   \n",
       "No Edges                                   False         True        False   \n",
       "Setting      Dataset      Proxy                                              \n",
       "Inductive    amazon_photo Aleatoric  0.47  0.04  0.33  0.02  0.51  0.02   \n",
       "                          Epistemic  0.49  0.03  0.37  0.02  0.51  0.02   \n",
       "             citeseer     Aleatoric  0.57  0.03  0.51  0.02  0.53  0.03   \n",
       "                          Epistemic  0.73  0.06  0.73  0.08  0.56  0.05   \n",
       "             coauthor_cs  Aleatoric  0.52  0.03  0.39  0.02  0.57  0.01   \n",
       "                          Epistemic  0.59  0.03  0.52  0.03  0.55  0.01   \n",
       "             cora_full    Aleatoric  0.45  0.04  0.38  0.03  0.52  0.03   \n",
       "                          Epistemic  0.52  0.04  0.44  0.05  0.52  0.06   \n",
       "             pubmed       Aleatoric  0.49  0.02  0.44  0.01  0.57  0.02   \n",
       "                          Epistemic  0.54  0.03  0.50  0.04  0.63  0.05   \n",
       "Transductive amazon_photo Aleatoric  0.45  0.04  0.32  0.02  0.53  0.03   \n",
       "                          Epistemic  0.48  0.05  0.35  0.03  0.52  0.02   \n",
       "             citeseer     Aleatoric  0.37  0.03  0.33  0.02  0.68  0.05   \n",
       "                          Epistemic  0.47  0.05  0.45  0.08  0.58  0.05   \n",
       "             coauthor_cs  Aleatoric  0.48  0.02  0.35  0.01  0.61  0.01   \n",
       "                          Epistemic  0.54  0.02  0.48  0.02  0.57  0.02   \n",
       "             cora_full    Aleatoric  0.35  0.03  0.30  0.02  0.61  0.02   \n",
       "                          Epistemic  0.43  0.04  0.37  0.04  0.59  0.05   \n",
       "             pubmed       Aleatoric  0.35  0.02  0.31  0.01  0.61  0.03   \n",
       "                          Epistemic  0.38  0.02  0.35  0.03  0.62  0.02   \n",
       "\n",
       "                                                                    \\\n",
       "Metric                                                               \n",
       "Experiment                                       Leave Out Classes   \n",
       "No Edges                                    True             False   \n",
       "Setting      Dataset      Proxy                                      \n",
       "Inductive    amazon_photo Aleatoric  0.79  0.04       0.81  0.05   \n",
       "                          Epistemic  0.71  0.03       0.82  0.05   \n",
       "             citeseer     Aleatoric  0.84  0.06       0.80  0.07   \n",
       "                          Epistemic  0.67  0.06       0.61  0.11   \n",
       "             coauthor_cs  Aleatoric  0.99  0.01       0.95  0.03   \n",
       "                          Epistemic  0.76  0.03       0.77  0.03   \n",
       "             cora_full    Aleatoric  0.91  0.05       0.93  0.03   \n",
       "                          Epistemic  0.71  0.04       0.72  0.04   \n",
       "             pubmed       Aleatoric  0.61  0.09       0.50  0.04   \n",
       "                          Epistemic  0.79  0.06       0.50  0.03   \n",
       "Transductive amazon_photo Aleatoric  0.77  0.05       0.76  0.06   \n",
       "                          Epistemic  0.70  0.04       0.78  0.05   \n",
       "             citeseer     Aleatoric  0.96  0.04       0.84  0.09   \n",
       "                          Epistemic  0.64  0.06       0.71  0.11   \n",
       "             coauthor_cs  Aleatoric  1.00  0.01       0.89  0.06   \n",
       "                          Epistemic  0.77  0.03       0.75  0.04   \n",
       "             cora_full    Aleatoric  0.92  0.05       0.95  0.02   \n",
       "                          Epistemic  0.75  0.05       0.74  0.05   \n",
       "             pubmed       Aleatoric  0.69  0.13       0.58  0.14   \n",
       "                          Epistemic  0.76  0.10       0.58  0.14   \n",
       "\n",
       "                                                                            \n",
       "Metric                                                                      \n",
       "Experiment                                             Normal               \n",
       "No Edges                                    True        False         True  \n",
       "Setting      Dataset      Proxy                                             \n",
       "Inductive    amazon_photo Aleatoric  0.74  0.04  0.48  0.03  0.18  0.05  \n",
       "                          Epistemic  0.71  0.03  0.53  0.03  0.32  0.08  \n",
       "             citeseer     Aleatoric  0.69  0.09  0.18  0.03  0.02  0.01  \n",
       "                          Epistemic  0.56  0.05  0.61  0.08  0.65  0.14  \n",
       "             coauthor_cs  Aleatoric  0.92  0.02  0.50  0.03  0.26  0.02  \n",
       "                          Epistemic  0.78  0.02  0.60  0.02  0.50  0.03  \n",
       "             cora_full    Aleatoric  0.84  0.03  0.31  0.05  0.12  0.03  \n",
       "                          Epistemic  0.67  0.05  0.48  0.05  0.28  0.06  \n",
       "             pubmed       Aleatoric  0.53  0.03  0.28  0.03  0.12  0.03  \n",
       "                          Epistemic  0.53  0.02  0.41  0.05  0.30  0.12  \n",
       "Transductive amazon_photo Aleatoric  0.75  0.02  0.49  0.02  0.18  0.03  \n",
       "                          Epistemic  0.71  0.03  0.53  0.03  0.30  0.05  \n",
       "             citeseer     Aleatoric  0.71  0.15  0.23  0.05  0.08  0.03  \n",
       "                          Epistemic  0.69  0.13  0.50  0.08  0.45  0.16  \n",
       "             coauthor_cs  Aleatoric  0.87  0.05  0.52  0.02  0.27  0.02  \n",
       "                          Epistemic  0.78  0.04  0.61  0.02  0.52  0.03  \n",
       "             cora_full    Aleatoric  0.90  0.04  0.33  0.03  0.18  0.04  \n",
       "                          Epistemic  0.73  0.07  0.52  0.05  0.38  0.06  \n",
       "             pubmed       Aleatoric  0.56  0.11  0.31  0.03  0.16  0.03  \n",
       "                          Epistemic  0.56  0.11  0.39  0.03  0.29  0.07  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "536132c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_proxy_agg.reset_index()\n",
    "df_tmp = df_tmp.melt(id_vars=[SETTING, DATASET, EXPERIMENT, NO_EDGES, PROXY], value_vars = [OOD_AUROC, OOD_AUCPR, MISCLASSICIFACTION_AUROC, MISCLASSICIFACTION_AUCPR], var_name='Metric')\n",
    "df_tmp = df_tmp[(df_tmp[METRIC] == MISCLASSICIFACTION_AUROC) | (df_tmp[METRIC] == MISCLASSICIFACTION_AUCPR)]\n",
    "df_tmp = df_tmp.pivot(index=[SETTING, DATASET, PROXY], columns=[METRIC, EXPERIMENT, NO_EDGES]).T.sort_index().T\n",
    "df_tmp.to_csv('~/laplace_all_datasets_misclassification_detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
